# -*- coding: utf-8 -*-
"""eloy-alvin-luna-dat-554-final-project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FkkLjVvxHeJ3EpYYCZ78VbYjRhlHWXtI

<font size="+4" color="black"><strong>Final Project - Data Analytics Capstone</strong></font>
<br>
<font size="+2" color="navy">DAT 554 - University of Illinois at Springfield</font>
<br>
<font size="+1" color="navy"><strong>Eloy Alvin Luna</strong> (<em>aluna21</em>)</font>
<br>

<font size="+3" color="fuchsia"><strong>Environment Preparation</strong></font>
<br>
<br>
<font size="+1" color="black"><strong><em>Setting up R in Google Colab:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# Loads the R extension while Python is running.
# Alternatively you can change the Runtime to R, but then it won't allow to import the drive.
# %load_ext rpy2.ipython

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Tells the operating system, and basic pre-installed packages.
# sessionInfo()

# Commented out IPython magic to ensure Python compatibility.
# %%R
# if (!requireNamespace("mltools", quietly = TRUE)) {
#   install.packages("mltools")
# }
# 
# if (!requireNamespace("dplyr", quietly = TRUE)) {
#   install.packages("dplyr")
# }
# 
# if (!requireNamespace("rpart", quietly = TRUE)) {
#   install.packages("rpart")
# }
# 
# if (!requireNamespace("randomForest", quietly = TRUE)) {
#   install.packages("randomForest")
# }
# 
# # For Naive Bayes
# if (!requireNamespace("e1071", quietly = TRUE)) {
#   install.packages("e1071")
# }

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Pops up a list of the CRAN packages currently available to you.
# library()

"""<br><br>
<font size="+1" color="black"><strong><em>Setting up the Drive:</em></strong></font>
* Activate this only if you are planning to load the file from your Google Drive.

"""

#from google.colab import drive
#drive.mount('/content/drive')

"""<br><br>
<font size="+3" color="fuchsia"><strong>Data Loading</strong></font>
* In this case, the file will need to be uploaded to Colab in order to be used in this Notebook.

"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# df.raw <- read.csv('/content/combinedAdultSurveys.csv', stringsAsFactors = FALSE, header = TRUE, encoding = "UTF-8", sep = ",", strip.white = TRUE)

"""<br><br>
<font size="+3" color="fuchsia"><strong>Data Exploration</strong></font>
<br>
<br>
<font size="+1" color="black"><strong><em>Displaying the structure:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# str(df.raw)

"""<br><br>
<font size="+1" color="black"><strong><em>Revealing the dimensions:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# dim(df.raw)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# nrow(df.raw)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# ncol(df.raw)

"""<br><br>
<font size="+1" color="black"><strong><em>Analyzing the columns:</em></strong></font>
* <font color="red">Note:</font> The <strong>columns</strong> will also be called <strong>features</strong> and <strong>variables</strong> interchangeably.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# colnames(df.raw)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# suppressPackageStartupMessages(library(dplyr))
# colsWithNumericValues <- names(select_if(df.raw, is.numeric))
# len <- length(colsWithNumericValues)
# cat("Quantity of Numeric variables: ", len, "\n \n")
# colsWithNumericValues

# Commented out IPython magic to ensure Python compatibility.
# %%R
# colsWithCategoricalValues <- names(df.raw %>% select(-all_of(colsWithNumericValues)))
# len <- length(colsWithCategoricalValues)
# cat("Quantity of Categorical variables:", len, "\n \n")
# colsWithCategoricalValues

"""<br><br>
<font size="+1" color="black"><strong><em>Searching for missing values:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # This code prints out a list of the columns with the number of their missing values.
# colSums(is.na(df.raw))

# Commented out IPython magic to ensure Python compatibility.
# %%R
# #Both MEDRXTRT_A and HLTHCOND_A have the same amount of missing values.
# missVals <- (13856 / 88701) * 100
# missVals

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # The following code search for infinity (positive and negative) values within a column and then prints them
# # in a frequency table. TRUE is for the infinity values.
# print(table(is.infinite(df.raw$SEX_A)))
# print("SEX_A")
# print(table(is.infinite(df.raw$AGEP_A)))
# print("AGEP_A")
# print(table(is.infinite(df.raw$HISPALLP_A)))
# print("HISPALLP_A")
# print(table(is.infinite(df.raw$PHSTAT_A)))
# print("PHSTAT_A")
# print(table(is.infinite(df.raw$HYPEV_A)))
# print("HYPEV_A")
# print(table(is.infinite(df.raw$CHLEV_A)))
# print("CHLEV_A")
# print(table(is.infinite(df.raw$CHDEV_A)))
# print("CHDEV_A")
# print(table(is.infinite(df.raw$ANGEV_A)))
# print("ANGEV_A")
# print(table(is.infinite(df.raw$MIEV_A)))
# print("MIEV_A")
# print(table(is.infinite(df.raw$STREV_A)))
# print("STREV_A")
# print(table(is.infinite(df.raw$ASEV_A)))
# print("ASEV_A")
# print(table(is.infinite(df.raw$CANEV_A)))
# print("CANEV_A")
# print(table(is.infinite(df.raw$DIBEV_A)))
# print("DIBEV_A")
# print(table(is.infinite(df.raw$COPDEV_A)))
# print("COPDEV_A")
# print(table(is.infinite(df.raw$ARTHEV_A)))
# print("ARTHEV_A")
# print(table(is.infinite(df.raw$DEMENEV_A)))
# print("DEMENEV_A")
# print(table(is.infinite(df.raw$ANXEV_A)))
# print("ANXEV_A")
# print(table(is.infinite(df.raw$DEPEV_A)))
# print("DEPEV_A")
# print(table(is.infinite(df.raw$MEDRXTRT_A)))
# print("MEDRXTRT_A")
# print(table(is.infinite(df.raw$HLTHCOND_A)))
# print("HLTHCOND_A")
# print(table(is.infinite(df.raw$BMICAT_A)))
# print("BMICAT_A")
# print(table(is.infinite(df.raw$SMOKELSEV_A)))
# print("SMOKELSEV_A")
# print(table(is.infinite(df.raw$PIPEEV_A)))
# print("PIPEEV_A")
# print(table(is.infinite(df.raw$CIGAREV_A)))
# print("CIGAREV_A")
# print(table(is.infinite(df.raw$SMKECIGST_A)))
# print("SMKECIGST_A")
# print(table(is.infinite(df.raw$SMKCIGST_A)))
# print("SMKCIGST_A")

"""<br><br>
<font size="+1" color="black"><strong><em>Identifying outliers:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# boxplot(df.raw$AGEP_A, na.action = FALSE, ylab = "Age", main = "Age", sub = "Boxplot")

# Commented out IPython magic to ensure Python compatibility.
# %%R
# q <- quantile(df.raw$AGEP_A, prob=c(0, 0.25, .5, .75, 1), type=1)
# Q1 <- q[[1]]
# cat("The first quartile (Q1): ", Q1, "\n")
# Q3 <- q[[3]]
# cat("The third quartile (Q3): ", Q3, "\n")
# iqr <- IQR(df.raw$AGEP_A)
# cat("The Interquartile Range (IQR): ", iqr, "\n")
# leftOrDown <- Q1 - (1.5 * iqr)
# rightOrUp <-Q3 + (1.5 * iqr)
# 
# outliers.df <- df.raw[df.raw$AGEP_A < leftOrDown | df.raw$AGEP_A > rightOrUp,  ]
# cat("The amount of outliers: ", nrow(outliers.df))

"""<br><br>
<font size="+3" color="fuchsia"><strong>Data Preprocessing</strong></font>
<br>
<br>
<font size="+1" color="black"><strong><em>Factorizing variables:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# df.clean <- df.raw

# Commented out IPython magic to ensure Python compatibility.
# %%R
# df.clean[ , 1]<- as.factor(df.clean[ , 1])
# df.clean[, 3:26] <- lapply(df.clean[, 3:26], as.factor)
# str(df.clean)

"""<br><br>
<font size="+1" color="black"><strong><em>Eliminating columns with too many missing values:</em></strong></font>
* <strong>Imputation</strong> could be used here, but since the two variables with missing value have <strong>15% of missing values each</strong>, and there are 26 columns in total, removing them seems to be more convenient for this study than keeping them.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # MEDRXTRT_A and HLTHCOND_A.
# df.clean <- df.clean[ , -c(19:20)]

# Commented out IPython magic to ensure Python compatibility.
# %%R
# colSums(is.na(df.clean))

"""<br><br>
<font size="+1" color="black"><strong><em>Removing rows with unwanted values:</em></strong></font>

* <font color="red">Note:</font> The <strong>rows</strong> will also be called <strong>observations</strong> interchangeably.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# unique(df.clean$SMKCIGST_A)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# df.clean <- df.clean[!(df.clean$SEX_A == "7" | df.clean$SEX_A == "9"), ]
# df.clean <- df.clean[!(df.clean$PHSTAT_A == "7" | df.clean$PHSTAT_A == "9"), ]
# df.clean <- df.clean[!(df.clean$HYPEV_A == "7" | df.clean$HYPEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$CHLEV_A == "7" | df.clean$CHLEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$CHDEV_A == "7" | df.clean$CHDEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$ANGEV_A == "7" | df.clean$ANGEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$MIEV_A == "7" | df.clean$MIEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$STREV_A == "7" | df.clean$STREV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$ASEV_A == "7" | df.clean$ASEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$CANEV_A == "7" | df.clean$CANEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$DIBEV_A == "7" | df.clean$DIBEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$COPDEV_A == "7" | df.clean$COPDEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$ARTHEV_A == "7" | df.clean$ARTHEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$DEMENEV_A == "7" | df.clean$DEMENEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$ANXEV_A == "7" | df.clean$ANXEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$DEPEV_A == "7" | df.clean$DEPEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$BMICAT_A == "9"), ]
# df.clean <- df.clean[!(df.clean$SMOKELSEV_A == "7" | df.clean$SMOKELSEV_A == "8" | df.clean$SMOKELSEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$PIPEEV_A == "7" | df.clean$PIPEEV_A == "8" | df.clean$PIPEEV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$CIGAREV_A == "7" | df.clean$CIGAREV_A == "8" | df.clean$CIGAREV_A == "9"), ]
# df.clean <- df.clean[!(df.clean$SMKECIGST_A == "4" | df.clean$SMKECIGST_A == "9"), ]
# df.clean <- df.clean[!(df.clean$SMKCIGST_A == "5" | df.clean$SMKCIGST_A == "9"), ]

"""<br><br>
<font size="+1" color="black"><strong><em>Discarding the unused levels:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# df.clean$SEX_A <- droplevels(df.clean$SEX_A)
# df.clean$PHSTAT_A <- droplevels(df.clean$PHSTAT_A)
# df.clean$HYPEV_A <- droplevels(df.clean$HYPEV_A)
# df.clean$CHLEV_A <- droplevels(df.clean$CHLEV_A)
# df.clean$CHDEV_A <- droplevels(df.clean$CHDEV_A)
# df.clean$ANGEV_A <- droplevels(df.clean$ANGEV_A)
# df.clean$MIEV_A <- droplevels(df.clean$MIEV_A)
# df.clean$STREV_A <- droplevels(df.clean$STREV_A)
# df.clean$ASEV_A <- droplevels(df.clean$ASEV_A)
# df.clean$CANEV_A <- droplevels(df.clean$CANEV_A)
# df.clean$DIBEV_A <- droplevels(df.clean$DIBEV_A)
# df.clean$COPDEV_A <- droplevels(df.clean$COPDEV_A)
# df.clean$ARTHEV_A <- droplevels(df.clean$ARTHEV_A)
# df.clean$DEMENEV_A <- droplevels(df.clean$DEMENEV_A)
# df.clean$ANXEV_A <- droplevels(df.clean$ANXEV_A)
# df.clean$DEPEV_A <- droplevels(df.clean$DEPEV_A)
# df.clean$BMICAT_A <- droplevels(df.clean$BMICAT_A)
# df.clean$SMOKELSEV_A <- droplevels(df.clean$SMOKELSEV_A)
# df.clean$PIPEEV_A <- droplevels(df.clean$PIPEEV_A)
# df.clean$CIGAREV_A <- droplevels(df.clean$CIGAREV_A)
# df.clean$SMKECIGST_A <- droplevels(df.clean$SMKECIGST_A)
# df.clean$SMKCIGST_A <- droplevels(df.clean$SMKCIGST_A)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# rowsRemoved <-nrow(df.raw) - nrow(df.clean)
# rowsRemoved
# percRemoved <- (rowsRemoved / nrow(df.raw)) * 100
# cat("The percentage of rows removed from the data frame:", as.character(round(percRemoved, 2)), "\n\n")

# Commented out IPython magic to ensure Python compatibility.
# %%R
# str(df.clean)

"""<br><br>
<font size="+1" color="black"><strong><em>Rearraging the dataframe:</em></strong></font>

<font color="red">Target variable</font>: <strong>MIEV_A</strong> (#9) = Ever been told you had a <strong>heart attack</strong>?

* Placing the Target variable at the end of the dataset.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# temp.df <- df.clean[ , -c(9)]
# temp.df[["MIEV_A"]] <- df.clean[ , 9]
# df.clean <- temp.df
# str(df.clean)

"""<br><br>
<font size="+3" color="fuchsia"><strong>Data Analysis</strong></font>
<br>
<br>
<font size="+1" color="black"><strong><em>Correlation:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SEX_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$SEX_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SEX_A vs MIEV_A (categorical vs categorical)
# mosaicplot(mgTable, ylab = "SEX_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For AGEP_A vs MIEV_A (numeric vs categorical)
# res.aov <- aov(AGEP_A ~ MIEV_A, data = df.clean)
# summary(res.aov)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For AGEP_A vs MIEV_A (numeric vs categorical)
# boxplot(df.clean$AGEP_A ~ df.clean$MIEV_A, ylab = "AGEP_A", xlab = "MIEV_A", main = "Boxplot")

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For HISPALLP_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$HISPALLP_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For HISPALLP_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "HISPALLP_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For PHSTAT_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$PHSTAT_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For PHSTAT_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "PHSTAT_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For HYPEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$HYPEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For HYPEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "HYPEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CHLEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$CHLEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CHLEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "CHLEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CHDEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$CHDEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CHDEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "CHDEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ANGEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$ANGEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ANGEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "ANGEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For STREV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$STREV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For STREV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "STREV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ASEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$ASEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ASEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "ASEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CANEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$CANEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CANEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "CANEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DIBEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$DIBEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DIBEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "DIBEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For COPDEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$COPDEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For COPDEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "COPDEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ARTHEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$ARTHEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ARTHEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "ARTHEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DEMENEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$DEMENEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DEMENEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "DEMENEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ANXEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$ANXEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For ANXEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "ANXEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DEPEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$DEPEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For DEPEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "DEPEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For BMICAT_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$BMICAT_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For BMICAT_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "BMICAT_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMOKELSEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$SMOKELSEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMOKELSEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "SMOKELSEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For PIPEEV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$PIPEEV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For PIPEEV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "PIPEEV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CIGAREV_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$CIGAREV_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For CIGAREV_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "CIGAREV_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMKECIGST_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$SMKECIGST_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMKECIGST_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "SMKECIGST_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMKCIGST_A vs MIEV_A  (categorical vs categorical)
# mgTable <- table(df.clean$MIEV_A , df.clean$SMKCIGST_A)
# chisq.test(mgTable)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # For SMKCIGST_A vs MIEV_A  (categorical vs categorical)
# mosaicplot(mgTable, ylab = "SMKCIGST_A", xlab = "MIEV_A", main = "Mosaic Graph", shade = TRUE)

"""<br>
<br>
<font size="+1" color="black"><strong><em>Features selection:</em></strong></font>
<br><br>

[see: Feature selection methods](https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html#random-feature-selection)

### Correlation methods:

1. <strong>Correlation</strong> methods determine variable importance by assessing the correlation between a feature and the outcome of interest. High (anti) correlation indicates an important feature, whereas low (anti) correlation indicates that a feature is not directly related to the outcome.

### Univariate and multivariate regression methods:

1. <strong>Univariate</strong> and <strong>multivariate</strong> regression perform feature selection by performing regression using a feature or set of features as predictors. The performance of the regression model is then measured using a metric. Training and testing of regression models are repeated multiple times using bootstraps.


### Special Methods:

1. <strong>No feature selection</strong>

* As the name suggests, the none method avoids feature selection altogether. All features are passed into a model. Feature order is randomly shuffled prior to building a model to avoid influence of the provided feature order.

2. <strong>Random feature selection</strong>

* The random method randomly draws features prior to model building. It does not assign a random variable importance to a feature. New features are drawn each time a model is built. All features are available for the draw, but only m features are drawn. Here m is the signature size that is usually optimised by hyperparameter optimisation.

<strong>From the correlation section:</strong>
1. SEX_A.....< 2.2e-16
2. AGEP_A....< 2e-16
3. HISPALLP_A....< 2.2e-16
4. PHSTAT_A.....< 2.2e-16
5. HYPEV_A....< 2.2e-16
6. CHLEV_A....< 2.2e-16
7. CHDEV_A.....2.2e-16
8. ANGEV_A.....2.2e-16
9. STREV_A.....2.2e-16
10. ASEV_A.....= 0.0001592
11. CANEV_A.....< 2.2e-16
12. DIBEV_A.....< 2.2e-16
13. COPDEV_A.....< 2.2e-16
14. ARTHEV_A.....< 2.2e-16
15. DEMENEV_A.....< 2.2e-16
16. ANXEV_A.....= 3.844e-10
17. DEPEV_A.....< 2.2e-16
18. BMICAT_A....< 2.2e-16
19. SMOKELSEV_A.....= 3.879e-10
20. PIPEEV_A.....< 2.2e-16
21. CIGAREV_A.....< 2.2e-16
22. SMKECIGST_A.....= 3.625e-07
23. SMKCIGST_A.....< 2.2e-16

Since all the features showed to be highly correlaed to the target variable, I chose to use <strong>Random feature selection</strong> instead to limit the data frame's variables to a smaller subset of them. <font color="red"><strong>Note: </strong>The professor requested to work with <strong>10 or less variables</strong> for this project.</font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# 
# general.linear.model.tuner <- function(qtyOfModels, qtyOfCols) {
#   cat("Accuracy", "-", "Seed", "-",  "Columns", "\n")
# 
#   bestAccuracy <- 0
#   s <- NULL
#   c <- NULL
#   train <- NULL
#   test <- NULL
#   val <- NULL
#   pred <- NULL
#   temp <- NULL
# 
#   seed <- 10
#   for (i in 1:qtyOfModels) {
#       set.seed(seed)
# 
#       # This will create a list of random columns indexes
#       rand <- sample(1:23, qtyOfCols, replace=FALSE)
#       rand <- sort(rand)
#       # This will create a data frame with the columns from that list
#       temp.df <- df.clean[ , c(rand)]
#       temp.df[["MIEV_A"]] <- df.clean[ , 24]
# 
#       # This randomize the order of the database by rows.
#       set.seed(seed)
#       temp.df <- temp.df[sample(nrow(temp.df)),]
# 
#       # Training and Testing
#       #
#       # 80% of the sample size
#       smp_size <- floor(0.8 * nrow(temp.df))
#       # set the seed to make your partition reproducible
#       set.seed(seed)
#       # Create a sample of the data
#       splitted.data <- sample(seq_len(nrow(temp.df)), size = smp_size)
#       # Partition the data using the sample created above.
#       training.data <- temp.df[splitted.data, ] # 80% of the entire data
#       testing.data <- temp.df[-splitted.data, ] # 20% of the entire data
# 
#       # Validation and Testing
#       #
#       smp_size <- floor(0.5 * nrow(testing.data))
#       set.seed(seed)
#       splitted.data <- sample(seq_len(nrow(testing.data)), size = smp_size)
#       validation.data <- testing.data[-splitted.data, ] # represents the 10% of the entire data and 50% of the testing data
#       testing.data <- testing.data[splitted.data, ] # represents the 10% of the entire data and 50% of the testing data
# 
#       model.glm <- glm(formula = MIEV_A ~ ., data = training.data, family = binomial(link = "logit"))
# 
#       predictions.glm <- predict(object = model.glm, newdata = validation.data[ , -ncol(validation.data)], type = "response")
# 
#       binary.predictions.glm <- ifelse(predictions.glm >= 0.50, 1, 0)
# 
#       # Evaluating model accuracy
#       val.Labels <- validation.data[ , ncol(validation.data)]
# 
#       total_predictions <- length(binary.predictions.glm)
# 
#       correct_predictions <- sum(binary.predictions.glm == val.Labels)
# 
#       accuracy <- correct_predictions / total_predictions
# 
#       if (i == 1){
#           bestAccuracy <- accuracy
#           s <- seed
#           c <- rand
#           train <- training.data
#           test <- testing.data
#           val <- validation.data
#           pred <- binary.predictions.glm
#           temp <- temp.df
#       } #end of first if-statement
#       if (accuracy > bestAccuracy){
#           bestAccuracy <- accuracy
#           s <- seed
#           c <- rand
#           train <- training.data
#           test <- testing.data
#           val <- validation.data
#           pred <- binary.predictions.glm
#           temp <- temp.df
#       } #end of second if-statement
# 
#       cat(accuracy, "-",  seed, "-", "(",  rand, ")", "\n")
# 
#       seed = seed + 1
#     } #end of for-loop
#   return(list(accuracy = bestAccuracy, seed = s, columns = c, all_data = temp, training_data = train, testing_data = test, validation.data = val, binary_predictions_glm = pred))
# 
# } #end of function

# Commented out IPython magic to ensure Python compatibility.
# %%R
# tunerResults <- general.linear.model.tuner(40, 9)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# str(tunerResults)

"""<br>
<br>
<font size="+1" color="black"><strong><em>Splitting the data:</em></strong></font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # The splitting was done within the function "general.linear.model.tuner".
# training.data <- tunerResults$training_data
# testing.data <- tunerResults$testing_data
# validation.data <- tunerResults$validation.data

# Commented out IPython magic to ensure Python compatibility.
# %%R
# dim(training.data)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# dim(testing.data)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# dim(validation.data)

"""<br>
<br>
<font size="+1" color="black"><strong><em>Models:</em></strong></font>
<br><br>

###<font color="red"><strong>Generalized Linear Models (glm)</strong></font>

<br>

Note: The term <strong>"general" linear model (GLM)</strong> usually refers to conventional linear regression models for a continuous response variable given continuous and/or categorical predictors.

Note: All the linear models <strong>but linear regression</strong> actually require normalization.

Note: <strong>Normalization</strong> is not needed for linear regression.

Note: You don't need to <strong>standardize</strong> unless your regression is regularized.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # The glm model was performed within the function "general.linear.model.tuner".
# # This are results of the best model:
# cat("Accuracy:", tunerResults$accuracy, "\n")
# cat("Amount of columns:", length(tunerResults$columns), "\n")
# cat("Columns:", tunerResults$columns, "\n")
# cat("Seed:", tunerResults$seed, "\n")

# Commented out IPython magic to ensure Python compatibility.
# %%R
# table(tunerResults$binary_predictions_glm)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Note: if the predictions end up being of only one class, your Confusion Matrix will show only
# # one column. The same can happens with the rows.
# conf_matrix <- table(validation.data[, ncol(validation.data)], tunerResults$binary_predictions_glm)
# 
# # Sets the custom names for rows and columns
# if (length(colnames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     colnames(conf_matrix) <- custom_names
# }else{
#     if (colnames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         colnames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         colnames(conf_matrix) <- custom_names
#     }
# }
# 
# if (length(rownames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     rownames(conf_matrix) <- custom_names
# }else{
#     if (rownames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         rownames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         rownames(conf_matrix) <- custom_names
#     }
# }
# 
# print(conf_matrix)
# #     0  1
# # 0  TN  FP
# # 1  FN  TP

# Commented out IPython magic to ensure Python compatibility.
# %%R
# #str(conf_matrix)
# #rownames(conf_matrix)
# #colnames(conf_matrix)
# length(colnames(conf_matrix))
# colnames(conf_matrix) == 1

"""###<font color="red"><strong>Random Forest</strong></font>

<br>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# suppressPackageStartupMessages(library(randomForest))

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Tuning the random forest in order to find the best mtry (Number of variables randomly sampled as candidates at each split.)
# bestmtry <- tuneRF(x = training.data[ , -ncol(training.data)], y = training.data[, ncol(training.data)], stepFactor = 1.5, improve=0.01, ntree = 500)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# classifier = randomForest(x = training.data[ , -ncol(training.data)],
#                           y = training.data[, ncol(training.data)],
#                           ntree = 500, mtry = 4, random_state = 0)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# random.forest.predictions = predict(classifier, newdata = validation.data[-ncol(validation.data)])

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Evaluating model accuracy
# val.Labels <- validation.data[ , ncol(validation.data)]
# total_predictions <- length(random.forest.predictions)
# correct_predictions <- sum(random.forest.predictions == val.Labels)
# accuracy <- correct_predictions / total_predictions
# cat(accuracy)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Note: if the predictions end up being of only one class, your Confusion Matrix will show only
# # one column. The same can happens with the rows.
# conf_matrix <- table(validation.data[, ncol(validation.data)], random.forest.predictions)
# custom_names <- c("Neg", "Pos")
# 
# # Sets the custom names for rows and columns
# if (length(colnames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     colnames(conf_matrix) <- custom_names
# }else{
#     if (colnames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         colnames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         colnames(conf_matrix) <- custom_names
#     }
# }
# 
# if (length(rownames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     rownames(conf_matrix) <- custom_names
# }else{
#     if (rownames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         rownames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         rownames(conf_matrix) <- custom_names
#     }
# }
# print(conf_matrix)
# # TN FP
# # FN TP

"""###<font color="red"><strong>Na√Øve Bayes</strong></font>"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# suppressPackageStartupMessages(library(e1071))

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Extract the predictor variables and the target variable
# predictors_train <- training.data[, -ncol(training.data)]
# target_train <- as.factor(training.data$MIEV_A)
# 
# # Train the Naive Bayes model
# naive_bayes_model <- naiveBayes(predictors_train, target_train)
# 
# # Make predictions on the validation set
# predictors_val <- validation.data[, -ncol(validation.data)]
# predictions <- predict(naive_bayes_model, newdata = predictors_val)
# 
# # Evaluate model performance on the validation set
# conf_matrix <- table(validation.data$MIEV_A, predictions)
# print(conf_matrix)
#

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Evaluating model accuracy
# val.Labels <- validation.data[ , ncol(validation.data)]
# total_predictions <- length(predictions)
# correct_predictions <- sum(predictions == val.Labels)
# accuracy <- correct_predictions / total_predictions
# cat(accuracy)

"""###<font color="red"><strong>K Nearest Neighbor</strong></font>
* For this you will need to convert the factors to numbers (better to use <strong>one_hot</strong> for that purpose), and <strong>normalize</strong> the other numerical variables (not the factor ones).
<br>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Converting all the factors to numeric and separating the labels:
# #
# # Training
# knn.training.data <- training.data[ , -length(training.data)]
# knn.training.data[sapply(knn.training.data, is.factor)] <- lapply(knn.training.data[sapply(knn.training.data, is.factor)], as.numeric)
# knn.training.labels <- training.data[ , length(training.data)]
# # Validation
# knn.validation.data <- validation.data[ , -length(validation.data)]
# knn.validation.data[sapply(knn.validation.data, is.factor)] <- lapply(knn.validation.data[sapply(knn.validation.data, is.factor)], as.numeric)
# knn.validation.labels <- validation.data[ , length(validation.data)]
# # Testings
# knn.testing.data <- testing.data[ , -length(testing.data)]
# knn.testing.data[sapply(knn.testing.data, is.factor)] <- lapply(knn.testing.data[sapply(knn.testing.data, is.factor)], as.numeric)
# knn.testing.labels <- testing.data[ , length(testing.data)]

# Commented out IPython magic to ensure Python compatibility.
# %%R
# str(knn.training.data)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# str(knn.training.labels)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# train_scaled = scale(knn.training.data[ ,-length(knn.training.data)])
# test_scaled = scale(knn.validation.data[ ,-length(knn.validation.data)])

# Commented out IPython magic to ensure Python compatibility.
# %%R
# library(class)
# test_pred <- knn(train = train_scaled, test = test_scaled, cl = knn.training.labels, k=10)

"""##<font color="blue">Results:</font>

Model          Accuracy

GLM            0.03744915

RF             0.9626705

Naive Bayes    0.958124

KNN            none

<font color="blue">--------------------------------------------------------- </font>

### <font color="black">Running the <strong>best</strong> model on the <strong>testing</strong> data:</font>
"""

# Commented out IPython magic to ensure Python compatibility.
# %%R
# classifier = randomForest(x = training.data[ , -ncol(training.data)],
#                           y = training.data[, ncol(training.data)],
#                           ntree = 500, mtry = 4, random_state = 0)
# 
# test.random.forest.predictions = predict(classifier, newdata = testing.data[-ncol(testing.data)])
# # Evaluating model accuracy
# test.Labels <- testing.data[ , ncol(testing.data)]
# total_predictions <- length(test.random.forest.predictions)
# correct_predictions <- sum(test.random.forest.predictions == test.Labels)
# accuracy <- correct_predictions / total_predictions
# cat(accuracy)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # Note: if the predictions end up being of only one class, your Confusion Matrix will show only
# # one column. The same can happens with the rows.
# conf_matrix <- table(testing.data[, ncol(testing.data)], test.random.forest.predictions)
# custom_names <- c("Neg", "Pos")
# 
# # Sets the custom names for rows and columns
# if (length(colnames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     colnames(conf_matrix) <- custom_names
# }else{
#     if (colnames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         colnames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         colnames(conf_matrix) <- custom_names
#     }
# }
# 
# if (length(rownames(conf_matrix)) == 2){
#     custom_names <- c("Neg", "Pos")
#     rownames(conf_matrix) <- custom_names
# }else{
#     if (rownames(conf_matrix) == 1){
#         custom_names <- "Pos"
#         rownames(conf_matrix) <- custom_names
#     }else{
#         custom_names <- "Neg"
#         rownames(conf_matrix) <- custom_names
#     }
# }
# print(conf_matrix)
# # TN FP
# # FN TP

# Commented out IPython magic to ensure Python compatibility.
# %%R
# table(test.random.forest.predictions)

# Commented out IPython magic to ensure Python compatibility.
# %%R
# # A matrix to hold all the p-values with their variable's names.
# pValuesMatrix <- matrix(NA, nrow = nrow(training.data), ncol = 2)
# dim(pValuesMatrix)
# 
# for (i in 1:nrow(pValuesMatrix)){
#   pValuesMatrix[i,1] <- test.random.forest.predictions[i]
#   pValuesMatrix[i,2] <- test.Labels[i]
# }

# Commented out IPython magic to ensure Python compatibility.
# %%R
# cat("Pred", "\t", "Actual", "\n")
# for (i in 1:5){
#     cat(pValuesMatrix[i,1], "\t", pValuesMatrix[i,2], "\n")
# }